{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615940"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "job = pd.read_csv('/home/jovyan/MLProjects-1/job_descriptions.csv')\n",
    "job.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615940, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Id', 'Experience', 'Qualifications', 'Salary Range', 'location',\n",
       "       'Country', 'latitude', 'longitude', 'Work Type', 'Company Size',\n",
       "       'Job Posting Date', 'Preference', 'Contact Person', 'Contact',\n",
       "       'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits',\n",
       "       'skills', 'Responsibilities', 'Company', 'Company Profile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Id                 0\n",
      "Experience             0\n",
      "Qualifications         0\n",
      "Salary Range           0\n",
      "location               0\n",
      "Country                0\n",
      "latitude               0\n",
      "longitude              0\n",
      "Work Type              0\n",
      "Company Size           0\n",
      "Job Posting Date       0\n",
      "Preference             0\n",
      "Contact Person         0\n",
      "Contact                0\n",
      "Job Title              0\n",
      "Role                   0\n",
      "Job Portal             0\n",
      "Job Description        0\n",
      "Benefits               0\n",
      "skills                 0\n",
      "Responsibilities       0\n",
      "Company                0\n",
      "Company Profile     5478\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Exploratory data analysis - preprocessing of data\n",
    "\n",
    "#check for missing values\n",
    "\n",
    "print(job.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping records if critical columns are missing, in this case we see the only column where records are missing is Company Profile, still I would run the below code for a good practise\n",
    "\n",
    "job = job.dropna(subset=['Job Title', 'skills'])\n",
    "job['skills'] = job['skills'].fillna('')\n",
    "job['Job Description'] = job['Job Description'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills\n",
      "Interaction design principles User behavior and psychology Wireframing and prototyping tools Animation and micro-interaction design Collaborative design processes                                                                                   20580\n",
      "Network management Troubleshooting Network security IT certifications (e.g., CCNA)                                                                                                                                                                   17470\n",
      "UI design principles and best practices Graphic design tools (e.g., Adobe Photoshop, Illustrator) Typography and color theory Visual design and layout Responsive design                                                                             14036\n",
      "Social media platforms (e.g., Facebook, Twitter, Instagram) Content creation and scheduling Social media analytics and insights Community engagement Paid social advertising                                                                         13945\n",
      "User-centered design principles UX/UI design tools (e.g., Sketch, Adobe XD) Wireframing and prototyping Usability testing and user research Information architecture and user flows                                                                  13935\n",
      "Procurement processes Vendor assessment Contract negotiation Purchase order management Spend analysis Market research Supplier relationship management Data analysis Problem-solving Attention to detail Communication skills Financial acumen       13757\n",
      "Social media analytics tools (e.g., Google Analytics, Facebook Insights) Data analysis and reporting Social media ROI measurement Competitive analysis Trend identification                                                                          10659\n",
      "Quality assurance processes Testing methodologies (e.g., manual, automated) Bug tracking and reporting Test case development Regression testing                                                                                                      10541\n",
      "Search engine algorithms and ranking factors Keyword research and analysis On-page and off-page SEO optimization SEO tools (e.g., Google Analytics, SEMrush) SEO content strategy                                                                    10512\n",
      "Calendar management Travel coordination Meeting scheduling Correspondence and communication Office organization Confidentiality Time management Problem-solving Attention to detail Communication skills Technology proficiency (e.g., MS Office)    10496\n",
      "Name: count, dtype: int64\n",
      "location\n",
      "Seoul                        15104\n",
      "Apia                         15057\n",
      "Valletta                      7723\n",
      "Caracas                       7694\n",
      "Mogadishu                     7689\n",
      "Freetown                      7656\n",
      "Hanoi                         7649\n",
      "Sri Jayawardenepura Kotte     7649\n",
      "Baku                          7643\n",
      "San Marino                    7638\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking column distributions\n",
    "\n",
    "print(job['skills'].value_counts().head(10))\n",
    "print(job['location'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          social media managers oversee organizations so...\n",
       "1          frontend web developers design implement user ...\n",
       "2          quality control managers establish enforce qua...\n",
       "3          wireless network engineers design implement ma...\n",
       "4          conference manager coordinates manages confere...\n",
       "                                 ...                        \n",
       "1615935    mechanical design engineers create develop mec...\n",
       "1615936    director oversees organizations department tec...\n",
       "1615937    mechanical design engineers create develop mec...\n",
       "1615938    training coordinators design implement employe...\n",
       "1615939    wedding planners specialize organizing wedding...\n",
       "Name: Job Description, Length: 1615940, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning text columns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "job['skills'] = job['skills'].apply(clean_text)\n",
    "job['Job Description'] = job['Job Description'].apply(clean_text)\n",
    "job['Job Description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          social media managers oversee organizations so...\n",
       "1          frontend web developers design implement user ...\n",
       "2          quality control managers establish enforce qua...\n",
       "3          wireless network engineers design implement ma...\n",
       "4          conference manager coordinates manages confere...\n",
       "                                 ...                        \n",
       "1615935    mechanical design engineers create develop mec...\n",
       "1615936    director oversees organizations department tec...\n",
       "1615937    mechanical design engineers create develop mec...\n",
       "1615938    training coordinators design implement employe...\n",
       "1615939    wedding planners specialize organizing wedding...\n",
       "Name: Job Description, Length: 1615940, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job['Job Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates\n",
    "\n",
    "job = job.drop_duplicates(subset=['Job Title', 'skills', 'Job Description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (376, 23)\n",
      "Columns in the DataFrame: Index(['Job Id', 'Experience', 'Qualifications', 'Salary Range', 'location',\n",
      "       'Country', 'latitude', 'longitude', 'Work Type', 'Company Size',\n",
      "       'Job Posting Date', 'Preference', 'Contact Person', 'Contact',\n",
      "       'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits',\n",
      "       'skills', 'Responsibilities', 'Company', 'Company Profile'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#steps to get the combined matrix for vectorization\n",
    "#initial checks to confirm if we're good to build the combined matrix\n",
    "#1\n",
    "print(\"DataFrame shape:\", job.shape)\n",
    "print(\"Columns in the DataFrame:\", job.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'skills': 0\n",
      "Missing values in 'Job Description': 0\n",
      "Empty strings in 'skills': 0\n",
      "Empty strings in 'Job Description': 0\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "print(\"Missing values in 'skills':\", job['skills'].isnull().sum())\n",
    "print(\"Missing values in 'Job Description':\", job['Job Description'].isnull().sum())\n",
    "\n",
    "print(\"Empty strings in 'skills':\", (job['skills'].str.strip() == '').sum())\n",
    "print(\"Empty strings in 'Job Description':\", (job['Job Description'].str.strip() == '').sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 'skills' column:\n",
      "0    social media platforms eg facebook twitter ins...\n",
      "1    html css javascript frontend frameworks eg rea...\n",
      "2    quality control processes methodologies statis...\n",
      "3    wireless network design architecture wifi stan...\n",
      "4    event planning conference logistics budget man...\n",
      "Name: skills, dtype: object\n",
      "\n",
      "Sample 'Job Description' column:\n",
      "0    social media managers oversee organizations so...\n",
      "1    frontend web developers design implement user ...\n",
      "2    quality control managers establish enforce qua...\n",
      "3    wireless network engineers design implement ma...\n",
      "4    conference manager coordinates manages confere...\n",
      "Name: Job Description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "print(\"Sample 'skills' column:\")\n",
    "print(job['skills'].head())\n",
    "\n",
    "print(\"\\nSample 'Job Description' column:\")\n",
    "print(job['Job Description'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 'skills' column:\n",
      "0    social media platforms eg facebook twitter ins...\n",
      "1    html css javascript frontend frameworks eg rea...\n",
      "2    quality control processes methodologies statis...\n",
      "3    wireless network design architecture wifi stan...\n",
      "4    event planning conference logistics budget man...\n",
      "Name: skills, dtype: object\n",
      "\n",
      "Cleaned 'Job Description' column:\n",
      "0    social media managers oversee organizations so...\n",
      "1    frontend web developers design implement user ...\n",
      "2    quality control managers establish enforce qua...\n",
      "3    wireless network engineers design implement ma...\n",
      "4    conference manager coordinates manages confere...\n",
      "Name: Job Description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#cleaning was done above but re-running before we make the combined matrix\n",
    "import re\n",
    "\n",
    "# Define a cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function\n",
    "job['skills'] = job['skills'].apply(clean_text)\n",
    "job['Job Description'] = job['Job Description'].apply(clean_text)\n",
    "\n",
    "# Preview cleaned data\n",
    "print(\"Cleaned 'skills' column:\")\n",
    "print(job['skills'].head())\n",
    "\n",
    "print(\"\\nCleaned 'Job Description' column:\")\n",
    "print(job['Job Description'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills matrix shape: (376, 1027)\n",
      "Description matrix shape: (376, 1434)\n"
     ]
    }
   ],
   "source": [
    "#vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF vectorizers\n",
    "tfidf_skills = TfidfVectorizer(stop_words='english')\n",
    "tfidf_desc = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform both columns\n",
    "skills_matrix = tfidf_skills.fit_transform(job['skills'])\n",
    "desc_matrix = tfidf_desc.fit_transform(job['Job Description'])\n",
    "\n",
    "# Check the shapes of the matrices\n",
    "print(\"Skills matrix shape:\", skills_matrix.shape)\n",
    "print(\"Description matrix shape:\", desc_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined matrix shape: (376, 1932)\n"
     ]
    }
   ],
   "source": [
    "#combined matrix\n",
    "# Combine 'skills' and 'Job Description' into a single column\n",
    "job['combined'] = job['skills'] + ' ' + job['Job Description']\n",
    "\n",
    "# Re-run TF-IDF on the combined column\n",
    "tfidf_combined = TfidfVectorizer(stop_words='english')\n",
    "combined_matrix = tfidf_combined.fit_transform(job['combined'])\n",
    "\n",
    "# Check the shape of the new combined matrix\n",
    "print(\"Combined matrix shape:\", combined_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Job Recommendations:\n",
      "             Job Title                                             skills  \\\n",
      "328     Data Scientist  machine learning algorithms python programming...   \n",
      "157       Data Analyst  machine learning algorithms libraries eg sciki...   \n",
      "258  Marketing Analyst  data analysis tools eg sql python data visuali...   \n",
      "986   Research Analyst  data analysis techniques research methodologie...   \n",
      "211       Data Analyst  data quality assessment improvement data profi...   \n",
      "\n",
      "                                       Job Description  \n",
      "328  machine learning engineers develop machine lea...  \n",
      "157  data scientists use expertise data analysis ma...  \n",
      "258  analyze data sets generate insights provide da...  \n",
      "986  data analyst researcher conducts research anal...  \n",
      "211  data quality analysts ensure accuracy complete...  \n"
     ]
    }
   ],
   "source": [
    "#recommender system: recommending top 5 jobs based on user input\n",
    "#calculating cosine similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example input from the user\n",
    "user_input = \"python data analysis machine learning\"  # Replace with actual input\n",
    "\n",
    "# Transform the user input into the same TF-IDF space\n",
    "user_vector = tfidf_combined.transform([user_input])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_scores = cosine_similarity(user_vector, combined_matrix)\n",
    "\n",
    "# Get the top N job recommendations\n",
    "top_n = 5  # Number of recommendations\n",
    "top_indices = similarity_scores[0].argsort()[-top_n:][::-1]  # Indices of top N scores\n",
    "\n",
    "# Display the top recommendations\n",
    "recommended_jobs = job.iloc[top_indices][['Job Title', 'skills', 'Job Description']]\n",
    "print(\"Top Job Recommendations:\")\n",
    "print(recommended_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Job Title                                             skills  \\\n",
      "328     Data Scientist  machine learning algorithms python programming...   \n",
      "157       Data Analyst  machine learning algorithms libraries eg sciki...   \n",
      "258  Marketing Analyst  data analysis tools eg sql python data visuali...   \n",
      "986   Research Analyst  data analysis techniques research methodologie...   \n",
      "211       Data Analyst  data quality assessment improvement data profi...   \n",
      "\n",
      "                                       Job Description  Similarity Score  \n",
      "328  machine learning engineers develop machine lea...          0.642625  \n",
      "157  data scientists use expertise data analysis ma...          0.522936  \n",
      "258  analyze data sets generate insights provide da...          0.255087  \n",
      "986  data analyst researcher conducts research anal...          0.234594  \n",
      "211  data quality analysts ensure accuracy complete...          0.208804  \n"
     ]
    }
   ],
   "source": [
    "# Include similarity scores in the output: The similarity score is a numerical value that quantifies how closely two pieces of text (e.g., a resume \n",
    "# #and a job description) match in terms of content. It is calculated using cosine similarity, which is commonly used in text analysis.\n",
    "recommended_jobs['Similarity Score'] = similarity_scores[0][top_indices]\n",
    "print(recommended_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-docx in /opt/conda/lib/python3.11/site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.11/site-packages (from python-docx) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "###### building a recommender system based on resume\n",
    "\n",
    "!pip install PyPDF2 python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Resume Text: Managed\n",
      "hardware\n",
      "installation,\n",
      "support,\n",
      "and\n",
      "root\n",
      "cause\n",
      "analysis\n",
      "for\n",
      "company\n",
      "IT\n",
      "department.\n",
      "Provided\n",
      "remote\n",
      "and\n",
      "on-site\n",
      "assistance\n",
      "while\n",
      "ensuring\n",
      "all\n",
      "computer\n",
      "systems\n",
      "and\n",
      "programs\n",
      "were\n",
      "up-to-date.\n",
      "●\n",
      "Maintained\n",
      "employee\n",
      "relationships\n",
      "through\n",
      "consistent\n",
      "communications\n",
      "and\n",
      "technical\n",
      "support.\n",
      "●\n",
      "Researched\n",
      "and\n",
      "procured\n",
      "relevant\n",
      "hardware\n",
      "and\n",
      "directed\n",
      "installation\n",
      "tasks\n",
      "for\n",
      "company\n",
      "desktops,\n",
      "laptops,\n",
      "and\n",
      "servers.\n",
      "●\n",
      "Designed\n",
      "and\n",
      "installed\n",
      "hardware\n",
      "products\n",
      "and\n",
      "software\n",
      "systems\n",
      "including\n",
      "circuit\n",
      "boards\n",
      "an\n"
     ]
    }
   ],
   "source": [
    "#upload and extract text from resume\n",
    "\n",
    "import PyPDF2\n",
    "import docx\n",
    "\n",
    "def extract_text_from_file(file_path):\n",
    "    if file_path.endswith('.pdf'):\n",
    "        # Extract text from PDF\n",
    "        with open(file_path, 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = \" \".join(page.extract_text() for page in reader.pages)\n",
    "    elif file_path.endswith('.docx'):\n",
    "        # Extract text from Word document\n",
    "        doc = docx.Document(file_path)\n",
    "        text = \" \".join([p.text for p in doc.paragraphs])\n",
    "    elif file_path.endswith('.txt'):\n",
    "        # Extract text from plain text file\n",
    "        with open(file_path, 'r') as f:\n",
    "            text = f.read()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please upload a PDF, Word, or text file.\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "file_path = '/home/jovyan/MLProjects-1/Resume sample for WB testing.pdf'  # Replace with the path to the uploaded resume\n",
    "resume_text = extract_text_from_file(file_path)\n",
    "print(\"Extracted Resume Text:\", resume_text[:500])  # Display the first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1932 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess resume text\n",
    "\n",
    "resume_text_cleaned = clean_text(resume_text)  # Use the previously defined clean_text function\n",
    "\n",
    "# Transform resume text into the same TF-IDF space\n",
    "resume_vector = tfidf_combined.transform([resume_text_cleaned])\n",
    "resume_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Job Recommendations Based on Resume:\n",
      "                       Job Title  \\\n",
      "59         IT Support Specialist   \n",
      "85           Electrical Engineer   \n",
      "41         Systems Administrator   \n",
      "142        Network Administrator   \n",
      "479  Customer Support Specialist   \n",
      "\n",
      "                                                skills  \\\n",
      "59   desktop hardware software troubleshooting oper...   \n",
      "85   electronics design pcb layout embedded systems...   \n",
      "41   technical troubleshooting hardware software su...   \n",
      "142  system administration server maintenance activ...   \n",
      "479  help desk support ticket resolution troublesho...   \n",
      "\n",
      "                                       Job Description  \n",
      "59   desktop support technicians troubleshoot maint...  \n",
      "85   electronics hardware engineers develop design ...  \n",
      "41   support specialists provide technical assistan...  \n",
      "142  manage maintain organizations infrastructure i...  \n",
      "479  help desk analysts provide technical support a...  \n"
     ]
    }
   ],
   "source": [
    "#calculate similarity and recommend job\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_scores = cosine_similarity(resume_vector, combined_matrix)\n",
    "\n",
    "# Get the top N job recommendations\n",
    "top_n = 5  # Number of recommendations\n",
    "top_indices = similarity_scores[0].argsort()[-top_n:][::-1]\n",
    "\n",
    "# Display the top recommended jobs\n",
    "recommended_jobs = job.iloc[top_indices][['Job Title', 'skills', 'Job Description']]\n",
    "print(\"Top Job Recommendations Based on Resume:\")\n",
    "print(recommended_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###measuring the accuracy\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"resume\": \"python machine learning data analysis\",\n",
    "        \"relevant_jobs\": [\"Data Scientist\", \"Machine Learning Engineer\"]\n",
    "    },\n",
    "    {\n",
    "        \"resume\": \"digital marketing social media campaigns\",\n",
    "        \"relevant_jobs\": [\"Social Media Manager\", \"Marketing Specialist\"]\n",
    "    },\n",
    "    # Add more test cases\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs(resume_text, top_n=5):\n",
    "    # Preprocess the resume text\n",
    "    resume_text_cleaned = clean_text(resume_text)\n",
    "    resume_vector = tfidf_combined.transform([resume_text_cleaned])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_scores = cosine_similarity(resume_vector, combined_matrix)\n",
    "\n",
    "    # Get top recommendations\n",
    "    top_indices = similarity_scores[0].argsort()[-top_n:][::-1]\n",
    "    return job.iloc[top_indices]['Job Title'].tolist()  # Return job titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5 for resume: 0.2\n",
      "Precision@5 for resume: 0.4\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(recommended_jobs, relevant_jobs, k):\n",
    "    recommended_top_k = recommended_jobs[:k]\n",
    "    relevant_count = sum(job in relevant_jobs for job in recommended_top_k)\n",
    "    return relevant_count / k\n",
    "\n",
    "# Example usage\n",
    "for test_case in test_data:\n",
    "    recommendations = recommend_jobs(test_case['resume'], top_n=5)\n",
    "    precision = precision_at_k(recommendations, test_case['relevant_jobs'], k=5)\n",
    "    print(f\"Precision@5 for resume: {precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 for resume: 0.5\n",
      "Recall@5 for resume: 1.0\n"
     ]
    }
   ],
   "source": [
    "def recall_at_k(recommended_jobs, relevant_jobs, k):\n",
    "    recommended_top_k = recommended_jobs[:k]\n",
    "    relevant_count = sum(job in relevant_jobs for job in recommended_top_k)\n",
    "    return relevant_count / len(relevant_jobs)\n",
    "\n",
    "# Example usage\n",
    "for test_case in test_data:\n",
    "    recommendations = recommend_jobs(test_case['resume'], top_n=5)\n",
    "    recall = recall_at_k(recommendations, test_case['relevant_jobs'], k=5)\n",
    "    print(f\"Recall@5 for resume: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for resume: 1.0\n",
      "MRR for resume: 0.5\n"
     ]
    }
   ],
   "source": [
    "def mean_reciprocal_rank(recommended_jobs, relevant_jobs):\n",
    "    for i, job in enumerate(recommended_jobs):\n",
    "        if job in relevant_jobs:\n",
    "            return 1 / (i + 1)  # Reciprocal rank\n",
    "    return 0  # No relevant job found\n",
    "\n",
    "# Example usage\n",
    "for test_case in test_data:\n",
    "    recommendations = recommend_jobs(test_case['resume'], top_n=10)\n",
    "    mrr = mean_reciprocal_rank(recommendations, test_case['relevant_jobs'])\n",
    "    print(f\"MRR for resume: {mrr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######enhancing the model as the above accuracy is not good enough\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Prepare data for Word2Vec (split sentences into tokens)\n",
    "corpus = [text.split() for text in job['combined']]\n",
    "\n",
    "# Train Word2Vec\n",
    "model = Word2Vec(corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Example: Generate vectors for a sentence\n",
    "def get_sentence_vector(sentence, model):\n",
    "    tokens = sentence.split()\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if vectors:\n",
    "        return sum(vectors) / len(vectors)\n",
    "    else:\n",
    "        return np.zeros(100)  # Default zero vector if no tokens found\n",
    "\n",
    "job['vector'] = job['combined'].apply(lambda x: get_sentence_vector(x, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.11/site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.43.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for job descriptions and resumes\n",
    "job['embedding'] = job['combined'].apply(lambda x: model.encode(x))\n",
    "resume_embedding = model.encode(resume_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "job['weighted_combined'] = 2 * job['skills'] + job['Job Description']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in /opt/conda/lib/python3.11/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /opt/conda/lib/python3.11/site-packages (from surprise) (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-surprise->surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-surprise->surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-surprise->surprise) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Prepare interaction data (user, job, rating)\n",
    "interaction_data = pd.DataFrame({\n",
    "    'user': ['user1', 'user2', 'user1', 'user3'],\n",
    "    'job': ['job1', 'job2', 'job3', 'job1'],\n",
    "    'rating': [5, 4, 3, 5]\n",
    "})\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(interaction_data, reader)\n",
    "\n",
    "# Train collaborative filtering model\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for a user\n",
    "predictions = algo.test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "# Simulate relevance scores (1 for relevant, 0 for irrelevant)\n",
    "true_relevance = [[1, 0, 1, 0, 0]]  # True relevance for top 5 jobs\n",
    "predicted_scores = [[0.8, 0.5, 0.7, 0.3, 0.1]]  # Predicted similarity scores\n",
    "\n",
    "ndcg = ndcg_score(true_relevance, predicted_scores, k=5)\n",
    "print(\"NDCG Score:\", ndcg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###re-measuring the accuracy\n",
    "\n",
    "\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"resume\": \"python machine learning data analysis\",\n",
    "        \"relevant_jobs\": [\"Data Scientist\", \"Machine Learning Engineer\"]\n",
    "    },\n",
    "    {\n",
    "        \"resume\": \"digital marketing social media campaigns\",\n",
    "        \"relevant_jobs\": [\"Social Media Manager\", \"Marketing Specialist\"]\n",
    "    },\n",
    "    # Add more test cases\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs(resume_text, top_n=5):\n",
    "    # Preprocess the resume text\n",
    "    resume_text_cleaned = clean_text(resume_text)\n",
    "    resume_vector = tfidf_combined.transform([resume_text_cleaned])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_scores = cosine_similarity(resume_vector, combined_matrix)\n",
    "\n",
    "    # Get top recommendations\n",
    "    top_indices = similarity_scores[0].argsort()[-top_n:][::-1]\n",
    "    return job.iloc[top_indices]['Job Title'].tolist()  # Return job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5 for resume: 0.2\n",
      "Precision@5 for resume: 0.4\n"
     ]
    }
   ],
   "source": [
    "def precision_at_k(recommended_jobs, relevant_jobs, k):\n",
    "    recommended_top_k = recommended_jobs[:k]\n",
    "    relevant_count = sum(job in relevant_jobs for job in recommended_top_k)\n",
    "    return relevant_count / k\n",
    "\n",
    "# Example usage\n",
    "for test_case in test_data:\n",
    "    recommendations = recommend_jobs(test_case['resume'], top_n=5)\n",
    "    precision = precision_at_k(recommendations, test_case['relevant_jobs'], k=5)\n",
    "    print(f\"Precision@5 for resume: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5 for resume: 0.5\n",
      "Recall@5 for resume: 1.0\n"
     ]
    }
   ],
   "source": [
    "def recall_at_k(recommended_jobs, relevant_jobs, k):\n",
    "    recommended_top_k = recommended_jobs[:k]\n",
    "    relevant_count = sum(job in relevant_jobs for job in recommended_top_k)\n",
    "    return relevant_count / len(relevant_jobs)\n",
    "\n",
    "# Example usage\n",
    "for test_case in test_data:\n",
    "    recommendations = recommend_jobs(test_case['resume'], top_n=5)\n",
    "    recall = recall_at_k(recommendations, test_case['relevant_jobs'], k=5)\n",
    "    print(f\"Recall@5 for resume: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for resume: 1.0\n",
      "MRR for resume: 0.5\n"
     ]
    }
   ],
   "source": [
    "def mean_reciprocal_rank(recommended_jobs, relevant_jobs):\n",
    "    for i, job in enumerate(recommended_jobs):\n",
    "        if job in relevant_jobs:\n",
    "            return 1 / (i + 1)  # Reciprocal rank\n",
    "    return 0  # No relevant job found\n",
    "\n",
    "# Example usage\n",
    "for test_case in test_data:\n",
    "    recommendations = recommend_jobs(test_case['resume'], top_n=10)\n",
    "    mrr = mean_reciprocal_rank(recommendations, test_case['relevant_jobs'])\n",
    "    print(f\"MRR for resume: {mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Combined Matrix Shape: (376, 2279)\n"
     ]
    }
   ],
   "source": [
    "###another attempt for improvement\n",
    "\n",
    "# Create a weighted combined text column\n",
    "job['weighted_combined'] = 2 * job['skills'] + ' ' + job['Job Description']\n",
    "\n",
    "# Vectorize the weighted combined text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_combined = TfidfVectorizer(stop_words='english')\n",
    "combined_matrix = tfidf_combined.fit_transform(job['weighted_combined'])\n",
    "\n",
    "print(\"Weighted Combined Matrix Shape:\", combined_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_jobs(resume_text, top_n=5):\n",
    "    resume_text_cleaned = clean_text(resume_text)\n",
    "    resume_vector = tfidf_combined.transform([resume_text_cleaned])\n",
    "    similarity_scores = cosine_similarity(resume_vector, combined_matrix)\n",
    "    top_indices = similarity_scores[0].argsort()[-top_n:][::-1]\n",
    "    return job.iloc[top_indices][['Job Title', 'skills', 'Job Description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Job Title  \\\n",
      "41         Systems Administrator   \n",
      "59         IT Support Specialist   \n",
      "616             IT Administrator   \n",
      "612           Network Technician   \n",
      "355  Customer Support Specialist   \n",
      "\n",
      "                                                skills  \\\n",
      "41   technical troubleshooting hardware software su...   \n",
      "59   desktop hardware software troubleshooting oper...   \n",
      "616  system administration network administration t...   \n",
      "612  network troubleshooting support network config...   \n",
      "355  technical troubleshooting customer support too...   \n",
      "\n",
      "                                       Job Description  \n",
      "41   support specialists provide technical assistan...  \n",
      "59   desktop support technicians troubleshoot maint...  \n",
      "616  system administrators manage maintain computer...  \n",
      "612  network support specialists provide technical ...  \n",
      "355  technical support specialists assist customers...  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for job postings\n",
    "job['embedding'] = job['weighted_combined'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Generate embedding for resume\n",
    "resume_text_cleaned = clean_text(resume_text)\n",
    "resume_embedding = model.encode(resume_text_cleaned)\n",
    "\n",
    "# Compute similarity\n",
    "import numpy as np\n",
    "job['similarity'] = job['embedding'].apply(lambda x: np.dot(resume_embedding, x) / \n",
    "                                           (np.linalg.norm(resume_embedding) * np.linalg.norm(x)))\n",
    "\n",
    "# Get top recommendations\n",
    "job = job.sort_values(by='similarity', ascending=False)\n",
    "top_jobs = job[['Job Title', 'skills', 'Job Description']].head(5)\n",
    "print(top_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_precision_recall(test_data, k=10):\n",
    "    total_precision, total_recall = 0, 0\n",
    "    for test_case in test_data:\n",
    "        recommendations = recommend_jobs(test_case['resume'], top_n=k)\n",
    "        total_precision += precision_at_k(recommendations, test_case['relevant_jobs'], k)\n",
    "        total_recall += recall_at_k(recommendations, test_case['relevant_jobs'], k)\n",
    "    \n",
    "    avg_precision = total_precision / len(test_data)\n",
    "    avg_recall = total_recall / len(test_data)\n",
    "    return avg_precision, avg_recall\n",
    "\n",
    "# Example usage\n",
    "avg_precision, avg_recall = evaluate_precision_recall(test_data, k=10)\n",
    "print(f\"Precision@10: {avg_precision}\")\n",
    "print(f\"Recall@10: {avg_recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
